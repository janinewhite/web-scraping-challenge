{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T19:52:35.587098Z",
     "start_time": "2019-11-17T19:52:35.583132Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import config as cfg\n",
    "import tweepy as tw\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T17:36:35.717420Z",
     "start_time": "2019-11-17T17:36:35.711435Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "chrome_path = \"C:/Users/janin/OneDrive/Documents/GitHub/chromedriver.exe\"\n",
    "mars_sites = [{\"Name\":\"NASA Mars Explorer News\",\n",
    "               \"URL\":\"https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\",\n",
    "               \"Type\":\"News\",\n",
    "               \"Link Stem\":\"https://mars.nasa.gov\"\n",
    "              },\n",
    "              {\"Name\":\"JPL Mars Images\",\n",
    "               \"URL\":\"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\",\n",
    "               \"Type\":\"Featured Image\",\n",
    "               \"Link Stem\":\"https://www.jpl.nasa.gov\"\n",
    "              },\n",
    "              {\"Name\":\"Mars Weather\",\n",
    "               \"URL\":\"https://twitter.com/marswxreport?lang=en\",\n",
    "               \"Type\":\"Weather\"\n",
    "              },\n",
    "              {\"Name\":\"Mars Facts\",\n",
    "               \"URL\":\"https://space-facts.com/mars/\",\n",
    "               \"Type\":\"Facts\"\n",
    "              },\n",
    "              {\"Name\":\"Mars Hemispheres\",\n",
    "               \"URL\":\"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\",\n",
    "               \"Type\":\"Hemispheres\"\n",
    "              }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T17:36:36.368208Z",
     "start_time": "2019-11-17T17:36:36.364046Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def init_browser():\n",
    "    executable_path = {\"executable_path\": chrome_path}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T17:36:37.099492Z",
     "start_time": "2019-11-17T17:36:37.095997Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_page(url):\n",
    "    browser = init_browser()\n",
    "    browser.visit(url)\n",
    "    html = browser.html\n",
    "    return BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T17:36:37.935622Z",
     "start_time": "2019-11-17T17:36:37.928470Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scrape_news(site):\n",
    "    print(\"News Article\")\n",
    "    print(\"____________\")\n",
    "    soup = get_page(site['URL'])\n",
    "    article = {}\n",
    "    articles = soup.find_all(\"div\",class_ = \"list_text\")\n",
    "    latest_date = datetime(2000, 1, 1, 0, 0)\n",
    "    article_url = \"\"\n",
    "    article_title = \"\"\n",
    "    description = \"\"\n",
    "    for article in articles:\n",
    "        date_text = article.find(\"div\",class_=\"list_date\").text\n",
    "        article_date = datetime.strptime(date_text,'%B %d, %Y')\n",
    "        if article_date > latest_date:\n",
    "            latest_date = article_date\n",
    "            print(article_date)\n",
    "            article_link = article.find(\"div\",class_=\"content_title\")\n",
    "            article_url = f\"{site['Link Stem']}{article_link.a['href']}\"\n",
    "            print(article_url)\n",
    "            article_title = article_link.a.text.replace('\\n','').strip()\n",
    "            print(article_title)\n",
    "            description = article.find(\"div\", class_ = \"article_teaser_body\")\n",
    "            article_description = description.text.strip()\n",
    "            print(article_description)\n",
    "    print(\"____________\")\n",
    "    article[\"Detail\"] = article_title\n",
    "    article[\"Detail URL\"] = article_url\n",
    "    article[\"Detail Description\"] = article_description\n",
    "    return article\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T17:36:38.809615Z",
     "start_time": "2019-11-17T17:36:38.805643Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scrape_featured_image(site):\n",
    "    print(\"Featured Image\")\n",
    "    print(\"____________\")\n",
    "    soup = get_page(site['URL'])\n",
    "    article = {}\n",
    "    image = soup.find(\"article\",class_=\"carousel_item\")\n",
    "    print(image[\"alt\"])\n",
    "    image_style = image[\"style\"]\n",
    "    image_link = image_style[image_style.find(\"'\")+1:]\n",
    "    image_link = image_link[:image_link.find(\"'\")]\n",
    "    print(image_link)\n",
    "    article[\"Detail\"] = image[\"alt\"]\n",
    "    article[\"Detail URL\"] = f\"{site['Link Stem']}{image_link}\"\n",
    "    article[\"Detail Description\"] = \"Jet Propulsion Laboratory Featured Image\"\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T20:53:22.442856Z",
     "start_time": "2019-11-17T20:53:22.434905Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_Mars_weather():\n",
    "    print(\"Mars Weather\")\n",
    "    print(\"____________\")\n",
    "    # Use API to get latest Mars Weather tweet\n",
    "    consumer_key = cfg.Twitter_Consumer_API_Key\n",
    "    consumer_secret = cfg.Twitter_Consumer_Secret_API_Key\n",
    "    access_token = cfg.Twitter_Access_Token\n",
    "    access_token_secret = cfg.Twitter_Access_Token_Secret\n",
    "    auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret) \n",
    "    api = tw.API(auth)\n",
    "    status = api.user_timeline(\"MarsWxReport\",count=1,page=1)\n",
    "    #json_str = json.dumps(status[0]._json)\n",
    "    #parsed = json.loads(json_str)\n",
    "    #print(json.dumps(parsed, indent=4, sort_keys=True))\n",
    "    entities = status[0].entities\n",
    "    urls = dict(entities[\"urls\"][0])\n",
    "    last_tweet_url = \"\"\n",
    "    for key in urls.keys():\n",
    "        if key == \"expanded_url\":\n",
    "            last_tweet_url = urls[key]\n",
    "    print(last_tweet_url)\n",
    "    # Scrape text of latest tweet\n",
    "    soup = get_page(last_tweet_url)\n",
    "    tweet = soup.find(\"div\",class_=\"js-tweet-text-container\")\n",
    "    tweet_text = tweet.p.text.replace('\\n','').strip()\n",
    "    tweet_text = tweet_text[:(tweet_text.find(\"hPapic.twitter.com\")-1)]\n",
    "    print(tweet_text)\n",
    "    article = {}\n",
    "    article[\"Detail\"] = tweet_text\n",
    "    article[\"Detail URL\"] = last_tweet_url\n",
    "    article[\"Detail Description\"] = \"Mars Weather Tweet\"\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T20:53:23.487376Z",
     "start_time": "2019-11-17T20:53:23.481663Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_post(site):\n",
    "    post = {}\n",
    "    post.update({\"Site\":site[\"Name\"]})\n",
    "    url = site[\"URL\"]\n",
    "    post[\"Site URL\"] = url\n",
    "    site_type = site[\"Type\"]\n",
    "    post[\"Site Type\"] = site_type\n",
    "    details = {}\n",
    "    if site['Type'] == \"News\":\n",
    "        details = scrape_news(site)\n",
    "    elif site['Type'] == \"Featured Image\":\n",
    "        details = scrape_featured_image(site)\n",
    "    elif site['Type'] == \"Weather\":\n",
    "        details = get_Mars_weather()\n",
    "    post[\"Detail\"] = details[\"Detail\"]\n",
    "    post[\"Detail URL\"] = details[\"Detail URL\"]\n",
    "    post[\"Detail Description\"] = details[\"Detail Description\"]\n",
    "    return post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-17T20:53:31.318634Z",
     "start_time": "2019-11-17T20:53:24.413675Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mars Weather\n",
      "____________\n",
      "https://twitter.com/i/web/status/1196063234924699649\n",
      "InSight sol 345 (2019-11-15) low -100.4ºC (-148.6ºF) high -23.9ºC (-11.1ºF)winds from the SSE at 5.4 m/s (12.0 mph) gusting to 20.2 m/s (45.3 mph)pressure at 6.80\n",
      "{'Site': 'Mars Weather', 'Site URL': 'https://twitter.com/marswxreport?lang=en', 'Site Type': 'Weather', 'Detail': 'InSight sol 345 (2019-11-15) low -100.4ºC (-148.6ºF) high -23.9ºC (-11.1ºF)winds from the SSE at 5.4 m/s (12.0 mph) gusting to 20.2 m/s (45.3 mph)pressure at 6.80', 'Detail URL': 'https://twitter.com/i/web/status/1196063234924699649', 'Detail Description': 'Mars Weather Tweet'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "site = mars_sites[2]\n",
    "post = get_post(site)\n",
    "print(post)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "db = client.mars_db\n",
    "collection = db.items\n",
    "for site in mars_sites:\n",
    "    response = requests.get(site[\"URL\"])\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    results = soup.find_all('li', class_=site[\"Class\"])\n",
    "    for result in results:\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
